---
title: "Reproducibility workshop"
author: "Eirini Zormpa"
date: "5th of June 2020"
output:
  html_document: 
    code_folding: show
    highlight: tango
    bibliography: bibliography.bib
    theme: flatly
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

In this workshop we'll go through some basics on how to create, structure, and document reproducible projects in R.
By the end of this workshop you will have created an online version of that project that everyone can interact with **without having to download anything**. In the process you'll also get some practice with git and GitHub.

Prerequisites:

* R and R Studio are installed
* git is installed
* git and R Studio have been connected
* you have created a GitHub account
* you have created an R project with version control from [here](https://github.com/eirini-zormpa/IMPRSConf2020).

Your level of R proficiency really doesn't matter for this, most interaction with code will be basically incidental.
That being said, you will have a chance to explore some data and practice whatever R skills you feel like practicing (data wrangling, plotting, or analysis) if you feel like it.

You also don't need to be super comfortable with Git.
We will not be doing anything particularly advanced here and I will always include the commands you will need.
In fact, everything we are doing should be possible through the R Studio IDE for git.

# Getting started
## Definitions
Before we get started, it's probably useful to agree on some definitions.
Thrilling stuff, I know, but bear with me.
*Reproducibility* has been taken to mean a variety of things, but here by reproducibility I mean *the ability to use someone else's data and code to get the same results they did*.
You could also call that *computational reproducibility*.
I quite like the chart from the [Turing Way](https://the-turing-way.netlify.app/reproducibility/03/definitions), reproduced below [@turing_way2019]:

![](images/turing_way_reproducibility.PNG)

## Why does reproducibility matter?
You're in this workshop already, so I'm guessing you have your own answers to this, but here's my two cents:

* reproducibility is a minimum requirement for verifying research.
* reproducibility can make you more organised and save you time if you ever need to go back to some of your analyses.

So let's get started on **how to make your analyses more reproducible**.

# Project set-up
Most of what we'll cover today does not actually involve much code--we'll mostly work on setting up projects with reproducibility in mind.

## Documentation
Good documentation is vital for helping others not only reproduce, but also understand your code.
As you may have noticed, this project has absolutely none if it.
That's because we'll be making it together!


### License
I cannot stress how important it is that you **license everything you share**.
Licenses are important because they tell others how they can use whatever it is you have shared.

**If you don't attach a license to your code/data/materials/whatever you're severely limiting how people can use it.**.

You hold the copyright of whatever it is you have created.
As you^[or often your employer] are the copyright holder, anyone who wants to use your work should technically ask for your permission to be do do.
Attaching a license to your work is like giving instructions to others about what they can do with it without having to ask you every time.
Technically, you could just come up with your own licenses for whatever you share.
But...

![](images/goldblum.gif)

There are **many** licenses out there that are well-recognised and should cover whatever it is you want people to be able to do with your work.
You may have heard of the Creative Commons (CC) licenses.
These are great for a lot of creative work, e.g. articles or presentations, but they should generally be avoided for software.
If you like the CC-BY license, a software license that gives similar permissions is the MIT license.

#### Practice
So how do we add a license to our project?
You can do this really easily from GitHub:

1. Click on `Create new file`
2. Name your new file "LICENSE"
3. Click on `Choose a license template`
4. Select the MIT license (you can also preview your changes at this point)
5. Add an informative commit message
6. Click on `Commit directly to the master branck`

Wow, we've actually made a change to this project!!
This means that you now have a file on your GitHub project that doesn't exist on the project version stored locally on your computer.
To get the file from GitHub to your local machine, you need to **pull** from GitHub.
Go to your R Studio and click on your Git tab (on the pane where your Environment is, by default on the top right).
There you will see a light blue arrow facingdownward.
Click on it!

You should now see the LICENSE file if you look at your folder!

### README
Now people know how they can use your work, but they don't know what your work is and whether they would want to use it!
This brings to another crucial piece of documentation you should include in **every single project**--the README file.
The contents of your README will depend on the project you're sharing, but it should generally cover:

* what your project is about
* installation instructions
* prerequisites (e.g. required software)
* license information
* other contributors


The above are sections you'd expect to see in any project shared on GitHub.
When sharings scientific code that's associated with a publication, you should also share a 'reproducibility recipe'.
By that I mean telling people in what order they should run your scripts, in which script you run the analyses that are reported in your manuscript etc.
If reproducing your analysis takes a while (e.g. because one/some of the models takes a few hours to converge) that would also be useful information to include.

#### Practice
You'll notice that GitHub really tries to get people to add README files.
It's already asking you to `Add a README`, so let's not disappoint GitHub!
To create a README file:

1. Click on the `Add a README` button
2. Edit the file to include relevant information (you don't need to spend too much time on this right now)
3. Write an informative commit message
4. Commit your changes

Again, make sure to go back to your R Studio and **pull your changes** from GitHub to your local repository.


### Codebook
Another important piece of documentation to share along with your data is a codebook.
Codebook is perhaps a confusing name for this, as it actually documents your **data**.
This should explain what the different variables mean, what values they can take, what their labels are and mean.

The `codebook` package can be used to automate the creation of machine-readable codebooks.

## Folder structure
It's generally a good idea to use a project-oriented workflow, such that everything that is needed to reproduce your project is contained in **one folder**.

Within that root project folder, you should organise your files in subfolders.
The specifics of what files you have will vary, but generally:

* have separate subfolders for your code, data, and manuscript
* use informative names for your subfolders (e.g. code, data, manuscript)
* separate your raw data from your processed data
  * ideally you never make any changes to your raw data manually: it's best to do all your processing with a script and save a copy of the processed files in a different folder

You can also check out some standardised formats, e.g, the [DRESS protocol](https://www.projecttier.org/tier-protocol/dress-protocol/).

### R Projects
R makes it really easy to use projects!
In fact, If you're seeing this file, you're actually already using an R project!
That's **awesome**.

What's so great about R projects you may ask?
Well, for one, they can save your computer from [Jenny Bryan's wrath](https://www.tidyverse.org/blog/2017/12/workflow-vs-script/).
![](images/computer_on_fire.PNG)

Seriously, though R projects:

* Are self-contained.
  * Everything that someone may need to reproduce your analysis **lives in the same project folder**.
* Start in a new session, giving you a clean environment without any loaded data, functions, or packages.
  * This way you know that anything that happens when running your script is because of what exists in your script.
  * i.e., no more `rm(list = ls())`
* Set the working directory to the project root
  * This way you can use relative paths starting from the project root that will work on **anyone's** computer, not just yours!
  * i.e., no more `setwd("C:\Users\path/only/you/have")`

For this project, we created an R project from version control.
You can also create a new project in a new folder or in an existing folder.
You can create R Projects easily from `File` -> `New project`, or from the other shortcuts on the toolbar.

You'll know that you're using R projects, because they create an icon in your folder with the extension `.Rproj`.
When you want to go back to working on that project, don't open the individual scripts you want to work on, but click on the `.Rproj` file instead.
That will open a fresh R session for you.

We now have a portable, well-documented project to work with, let's look at some code!

# Example code
For this workshop, we'll be using data from the World Happiness Reports (years 2015-2019), a survey used to rank the happiness of people in the participating countries.
I downloaded these data from [kaggle](https://www.kaggle.com/)--you can find the entry for this particular dataset [here](https://www.kaggle.com/unsdsn/world-happiness).

Base R comes with a lot of functions for wrangling and analysing data, but you can add even more functionality through packages.
In this workshop, I'll be using packages from the [`tidyverse`](https://www.tidyverse.org/), an "opinionated collection of R packages [...] with an underlying philosophy, grammar, and data structures".

Generally speaking, it's nice to load your packages at the beginning of the script.
That way whoever is looking at your script knows what packages they will need.
I like listing the install command at the beginning as well (commented out), so people can install packages if they want to.

```{r load_packages, collapse=TRUE}
# install.packages("readr")
# install.packages("janitor")
# install.packages("tidyr")
# install.packages("dplyr")
# install.packages("ggplot2")

# to read in data as tibbles
library(readr)
# for easy data (in this case name) cleaning
library(janitor)
# for tidying data
library(tidyr)
# for wrangling data
library(dplyr)
# for beautiful plots
library(ggplot2)
```

Loading the packages gives me some warnings.
These are okay to ignore, R is just telling me that I have loaded packages that share function names.
Whichever was loaded last will be the one called, but I can still access the masked function by specifying which package I want.
This won't really be an issue today, but something to keep in mind.

## Session info
It's really important to tell people what **software versions** you used for your analysis.
The reason it's important is that software updates can very easily break your code (e.g. the recent R 4.0.0 version release).
That is, if someone (including yourself) tries to run your code in 5 years, it's quite likely that some parts of it won't work.

If people know what versions last worked (and if they really care), they can always go back and try to reproduce the analysis with those versions.
That's *a lot* of work for the reproducer, but it's very easy to share, so why not!
An easy way to report these versions is by printing the session info at the beginning or the end of your analysis.
By the end of the workshop you'll (hopefully) know of better ways to help others reproduce your code.

```{r session_info}
sessionInfo()
```

## Relative paths
Before we do anything, we need to get some data into R.
Every time you want to read in data, import functions from a script, or export any files, you'll need to point to unique locations in your folders.

As I mentioned before, it's important to use **relative paths** as opposed to **absolute paths** when you do that.
An absolute path starts from the root directory and lists the full path from your root directory to the location you're trying to point to.
The problem with that is that the chances two people share an absolute path to any file are vanishingly small.
So, every time you include an absolute path in your scripts, you are writing code guaranteed to not work on someone else's computer.
Changing that code to the correct path is not that difficult, but it's also very easy to write relative paths instead, so that's what we're going to do.
A relative path does not start from the root, but rather from a given working directory.
Because we're using R projects, that given working directory is the folder in which the .Rproj file is located.

Now we know this, let's read in some data!
You can see below my feeble attempt to read in the data from 2019.
I mean... it works, but my computer is in danger!

```{r read_data_bad, message=FALSE}
setwd("C:/Users/eirin/Documents/MPI Psycholinguistics/Teaching/IMPRSConf2020")
ds <- read_csv("raw-data/2019.csv")
```

#### Practice
We can do better than this!
```{r read_data_good}
# read in the data using a relative path
# if you ran the code above feel free to use 'ds' when reimporting the data

```
**Hint**: you don't need to set the working directory anymore, R projects do that for you.

You might want to use the `here` package^[if you do, don't forget to include it in the 'Load packages' section] to create the relative paths.
```{r read_data_better}

```


Now that we got our data into R, let's see what it looks like!
```{r glimpse_data}
# glimpse is a function from the dplyr package that gives you a, well, glimpse of your tibbles.
glimpse(ds)
```

Before we go any further, we need to deal with these names.
Spaces are generally not allowed in column names^[Avoiding spaces is generally a good idea when naming folders or files too.] in R (here R is using the backticks `` to allow the spaces).
A really handy way to get clean names when using  this is by using the `janitor` package.
```{r clean_names}
ds = janitor::clean_names(ds)
```

Let's take a look at what this has done:
```{r check_names}
glimpse(ds)
```

Okay, that looks much better!

## Explore
Let's explore our data a little bit.
I'm from Greece and was curious to see how Greece ranks in this survey.
```{r greece_happiness}
# In R, '%>%' is the pipe symbol, which takes the output of a previous function and passes it on as the input to the next function 
ds %>% filter(country_or_region == "Greece")
```

#### Practice (optional)
Feel free to explore these data a little bit too!
```{r }
# pick a country (whichever country) and see where it ranks
# head on over to mentimeter and tell us what rank you got!

```

## Plot
We can also play around with plots a little bit.
Here I've made a lollipop plot of the 10 happiest countries, ordered by their overall score.

```{r rank_lollipop}
ds %>%
  filter(overall_rank <= 10) %>%
  arrange(desc(overall_rank)) %>%
  mutate(country_or_region = factor(country_or_region, levels = country_or_region)) %>%
  ggplot(aes(x=country_or_region, y=score)) +
  geom_point(size = 4, colour = "skyblue") + 
  geom_segment( aes(x=country_or_region, xend=country_or_region, y=6.5, yend=score)) +
  coord_flip() +
  theme_bw() +
  labs(x = "Overall happiness score", y = "")
```

Well according to this, I should be happy to have moved to the Netherlands!

#### Practice (optional)
```{r your_plot}
# feel free to practice your ggplot2 skills here if you like--you can plot whatever you find interesting.
# the data for previous years are also available so, for example, you could explore how the ranking of countries may have changed.
```

# Binder
